## Supervised Learning Introduction

Supervised learning is when we train the model with data that is well-labelled, which means data is already tagged with the correct answer. The aim of a supervised learning algorithm is to find a mapping function to map the input variable (x) with the output variable (y),

It is classified into two categories of algorithms:
- Classification
- Regression

### Classification

A classification problem is when the output variable is a category, such as "red" or "blue", "yes" or "no".

Some popular classification algorithms are:
- Logistic Regression
- Random Forest Classification
- Decision Tree Classification
- Support Vector Machines
- K-Nearest Neighbors
- Naive Bayes

#### Logistic Regression

#### Random Forest

#### Decision Trees

#### Support Vector Machines


### Regression

A regression problem is when the output variable is a real value, such as "5'3''" as height, "23cm" as length.

Some popular regression algorithms are:
- Linear Regression
- Polynomial Regression
- Random Forest Regression
- Decision Tree Regression
- Support Vector Regression
- Principle Components Regression

### Datasets
All the datasets are from Kaggle and the project selection is guided by this link https://chirpset.com/t/topic/299